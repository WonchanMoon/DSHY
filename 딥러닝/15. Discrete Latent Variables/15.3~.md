---
날짜: 2025-02-16
완료: false
tags:
---

## 15.3 Expectation-Maximization Algorithm
- EM 알고리즘은 **잠재 변수(Latent Variable)** 가 포함된 확률 모델에서 **최대 가능도(MLE, Maximum Likelihood Estimation) 또는 최대 사후 확률(MAP, Maximum a Posteriori)** 을 추정하는 방법이다. 보통은 MLE로 진행
- 왜 해야하는가?
	- **불완전 데이터(Incomplete Data)**: 현실에서는 잠재 변수 $Z$를 모른다. 이때 **주어진 $X$만으로 $\theta$를 찾기 어렵다**.
	- MLE 함수의 해를 찾기 힘들다.
		- 미분이 힘들다.
### EM algorithm 과정
- **E-Step (Expectation Step, 기대 단계)**
	- 현재의 파라미터$\theta^{old}$ 을 사용하여 잠재 변수$Z$의 사후 확률 분포를 계산
		- $p(\mathbf{Z} \mid \mathbf{X}, \theta^{\text{old}})$
	- 이 사후 분포를 이용해 **완전 데이터 log-likelihood의 기대값** $Q(\theta, \theta^{\text{old}})$을 계산
		- $Q(\theta, \theta^{\text{old}}) = \sum_{\mathbf{Z}} p(\mathbf{Z} \mid \mathbf{X}, \theta^{\text{old}}) \ln p(\mathbf{X}, \mathbf{Z} \mid \theta)$
- **M-Step (Maximization Step, 최대화 단계)**
	- 기대값 $Q(\theta, \theta^{\text{old}})$을 최대화 하는 새로운 파라미터 $\theta^{new}$ 를 찾음
		- $\theta^{\text{new}} = \arg\max_{\theta} Q(\theta, \theta^{\text{old}})$
		- 기대값을 최대화 하는 방향으로 업데이트
- **반복수행**
	- 반복할수록 불완전 데이터에 대한 가능도 $p(X|\theta)$가 증가한다.
![[Pasted image 20250216081442.png]]

## GMM
- 저번장에서 GMM 에서 어떻게 EM- algorithm이 적용될 수 있었는지를 확인
- [[15.1~15.2]]
- GMM은 데이터가 독립적(i.i.d.)이라고 가정하지만, **시간적인 순서가 있는 데이터(예: 음성, 주식 가격)** 를 모델링할 때는 **은닉 마르코프 모델(HMM)** 을 사용
- HMM은 가우시안 컴포넌트 간의 **전이 확률(transition probability)** 을 고려하여 확장한 모델.
![[Pasted image 20250216082109.png]]


## Mixtures of Bernoulli Distributions
- 이산 이진 변수를 대상으로 하는 혼합 모델
- **잠재 클래스 분석(latent class analysis)** 모델
$$p(x \mid \mu) = \prod_{i=1}^{D} \mu_i^{x_i} (1 - \mu_i)^{(1 - x_i)}$$
- 여기서 $\mathbf{x} = (x_1, \dots, x_D)^{T}$, $\boldsymbol{\mu} = (\mu_1, \dots, \mu_D)^{T}$  
- 개별 변수는 독립적이며, 평균과 공분산은 쉽게 구할 수 있음
	- $\mathbb{E}[\mathbf{x}] = \boldsymbol{\mu}$
	- $\mathrm{cov}[\mathbf{x}] = \mathrm{diag}(\mu_i (1 - \mu_i))$
- 혼합 모델
	- $p(x \mid \pi, \mu) = \sum_{k=1}^{K} \pi_k p(x \mid \mu_k)$ 
	- $p(\mathbf{z} \mid \boldsymbol{\pi}) = \prod_{k=1}^{K} \pi_k^{z_k}$
	- 완성된 log-likelihood 함수
$$\ln p(\mathbf{X}, \mathbf{Z} \mid \boldsymbol{\mu}, \boldsymbol{\pi}) = \sum_{n=1}^{N} \sum_{k=1}^{K} z_{nk} \left\{ \ln \pi_k + \sum_{i=1}^{D} \left[ x_{ni} \ln \mu_{ki} + (1 - x_{ni}) \ln (1 - \mu_{ki}) \right] \right\}$$
### EM 알고리즘
- E-Step: 책임도(Responsibility) 계산
	- 각 데이터 포인트가 특정 구성요소 k에 속할 확률(책임도):
		- $\gamma(z_{nk}) = \frac{\pi_k p(x_n \mid \mu_k)}{\sum_{j} \pi_j p(x_n \mid \mu_j)}$
	- $N_k$ 구성요소 $k$에 속하는 데이터의 효과적인 개수
		- $N_k = \sum_{n=1}^{N} \gamma(z_{nk})$
	- $X_k$ 책임도를 반영한 데이터 가중 평균
		- $\mathbf{X}_k = \sum_{n=1}^{N} \gamma(z_{nk}) x_n$
- M-Step: 파라미터 업데이트
	- 각 군집의 평균 업데이트
		- $\mu_k = \frac{\mathbf{X}_k}{N_k}$
	- 혼합 계수 업데이트
		- $\pi_k = \frac{N_k}{N}$

### 베르누이 모델의 특징
- 가능도 함수가 무한으로 발산하는 특이점이 없음
- 베르누이 분포의 가능도는 0~1 범위 내에서 정의 되므로, 극단적인 값이 나오지 않음

--- 


## Evidence Lower Bound
- 우리는 log likelihood 함수를 직접 최적화 하는 것이 어려움으로 이를 우회하는 방법을 찾음
- 잠재 변수 Z을 도입하여 완전 데이터 우도 함수 $p(\mathbf{X}, \mathbf{Z} \mid \theta)$ 를 최적화하는 접근법을 사용
- 우리는 다음식을 최적화 하는 게 목표
$$p(\mathbf{X} \mid \theta) = \sum_{\mathbf{Z}} p(\mathbf{X}, \mathbf{Z} \mid \theta)$$
- 하지만 $p(\mathbf{X} \mid \theta)$을 직접 최적화하는 것이 $Z$로 인해 어려기 때문에, 잠재변수 $Z$의 분포(변분 분포, variational distribution) $q(Z)$ 를 도입하여 변헝
- 다음 로그 가능도를 아래와 같이 분리
$$\ln p(\mathbf{X} \mid \theta) = \mathcal{L}(q, \theta) + KL(q \parallel p)$$
- $\mathcal{L}(q, \theta)$ : **변분 하한(variational lower bound)**
	- 우리가 최대화 해야 할 목표
	- 여기서 $\mathcal{L}(q, \theta)$은 다음과 같이 정의 
$$\mathcal{L}(q, \theta) = \sum_{\mathbf{Z}} q(\mathbf{Z}) \ln \left( \frac{p(\mathbf{X}, \mathbf{Z} \mid \theta)}{q(\mathbf{Z})} \right)$$

- $KL(q \parallel p)$ : **쿨백-라이블러 발산(Kullback-Leibler divergence)** (두 분포 사이의 차이를 측정)
	- **항상 0 이상**이며 $q(\mathcal{Z}) = p(\mathcal{Z} \mid X, \theta)$ 일때만 0이 된다.
	- 이는 $q(Z)$에 대한 기대값(expectation)을 나타내며, 최적화할 수 있는 대상
$$KL(q \parallel p) = - \sum_{\mathbf{Z}} q(\mathbf{Z}) \ln \left( \frac{p(\mathbf{Z} \mid \mathbf{X}, \theta)}{q(\mathbf{Z})} \right) \geq 0.$$

- 따라서, 변분 하한(ELBO)은 로그 우도의 하한을 제공함:
 $$\mathcal{L}(q, \theta) \leq \ln p(\mathbf{X} \mid \theta).$$
![[Pasted image 20250216100608.png]]


## EM revisited
- 실제로 EM 알고리즘을 사용할때 likelihood가 최대화하는지 분해 된 식을 활용하여 검증해보자

### E step
- $q(Z)$의 최적화 기능을 함
- 현재 파라미터 값이 $\theta^{\text{old}}$라고 하자
- E-스텝에서는 $q(Z)$를 최적화하여를 $\mathcal{L}(q, \theta^{\text{old}})$최대화하는 것이 목표
- 우리는 $q(Z)$가 사후확률과 $p(\mathcal{Z} \mid X, \theta^{\text{old}})$같아지는 순간을 얻을 수 있는데, 이경우 $KL$ 발산이 0이되는 경우로, 아래를 만족
$$ q(Z) = p(Z \mid X, \theta^{old}), \quad \mathcal{L}(q, \theta^{old}) = \ln p(X \mid \theta^{old}) $$
결과적으로 **하한($ELBO$)이 최대화**가 된다.
![[Pasted image 20250309075854.png]]
### M step
- 파라미터를 최적화 하는 기능을 함
- E-스탭이 끝나면 $q(Z)$는 고정된 상태이다.
- 이제 여기서 $\mathcal{L}(q, \theta)$ 를 $\theta$ 에 대해 최대화 함
	- 이 과정이 $\theta^{new} = \arg\max_{\theta} \mathcal{L}(q, \theta)$을 통해 업데이트 하는 과정
![[Pasted image 20250309075957.png]]
## Independent and identically distributed data
$$p(Z | \mathbf{X}, \theta) = \frac{p(\mathbf{X}, Z | \theta)}{\sum_{Z} p(\mathbf{X}, Z | \theta)}
= \frac{\prod_{n=1}^{N} p(x_n, z_n | \theta)}{\sum_{Z} \prod_{n=1}^{N} p(x_n, z_n | \theta)}
= \prod_{n=1}^{N} p(z_n | x_n, \theta)$$
- 우리가 E 단계에서 **"어떤 잠재 변수가 주어진 데이터에서 얼마나 가능성이 있는가?"** 를 계산해야함
- 이것을 사후 확률이라고 하는데, 해당 확률을 위와 같이 정리할 수 있음.
- 결론 적으로 각 데이터 포인트 $x_n$ 에 대한 **사후 확률 $p(z_n | \mathbf{x}_n, \theta)$을 개발적으로 계산** 할 수 있다는 의미가 됨

## Parameter priors
$p(\theta | \mathbf{X}) = \frac{p(\theta, \mathbf{X})}{p(\mathbf{X})}$ 을 변형하면 $\ln p(\theta | \mathbf{X}) = \ln p(\theta, \mathbf{X}) - \ln p(\mathbf{X})$와 같이 변경하능하고 최종적으론 아래와 같이 정리
$$\ln p(\theta | \mathbf{X}) = \mathcal{L}(q, \theta) + KL(q \| p) + \ln p(\theta) - \ln p(\mathbf{X}) 

\geq \mathcal{L}(q, \theta) + \ln p(\theta) - \ln p(\mathbf{X}).$$
여기서 $\ln{p(X)}$는 E-단계에선 상수로 볼 수 있음
M-단계에서 추가되는 $\ln{p(X)}$가 일종의 정규화 역활을 한다고 볼수 있고, 해당항이 가능도의 특이점을 제거하는 역할을 한다고 함 

## Generalized EM vs Sequential EM
- **GEM (Generalized EM)**
	- EM 알고리즘의 **M 단계를 완전히 최적화하지 않고**, 가능도를 증가시키는 방식으로 업데이트하는 변형 기법. 기울기 기반 최적화, 기대 조건부 최대화(ECM) 등을 활용 가능.
- **SEM (Sequential EM)**
	- EM 알고리즘을 **한 개의 데이터 포인트씩 점진적으로 업데이트**하는 방식. 데이터가 점진적으로 들어오는 환경에서 효율적으로 사용할 수 있으며, 빠른 수렴이 가능함.

| 비교 항목       | **GEM (Generalized EM)**                                                                                                             | **SEM (Sequential EM)**                                                                                                      |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |
| **개념**      | 기존 EM 알고리즘의 M 단계를 완전히 최적화하지 않고, 가능도(likelihood)를 증가시키는 방식으로 업데이트하는 방법                                                                | 기존 EM 알고리즘과 달리, 한 번의 업데이트에서 전체 데이터가 아니라 한 개의 데이터 포인트만 처리하는 방법                                                                |
| **E 단계**    | 기존 EM과 동일하게 수행됨                                                                                                                      | 하나의 데이터 포인트에 대해서만 책임도(responsibility) 계산                                                                                     |
| **M 단계**    | $\mathcal{L}(q, \theta)$를 완전히 최적화하지 않고, 증가시키는 방향으로만 업데이트                                                                             | M 단계에서도 전체 데이터를 한꺼번에 업데이트하지 않고, 새로운 데이터 포인트에 대한 충분 통계량을 점진적으로 업데이트                                                           |
| **적용 방식**   | M 단계의 계산이 어려운 경우 적용                                                                                                                  | 데이터가 점진적으로 입력되는 환경(예: 온라인 학습)에서 적용                                                                                           |
| **계산 복잡도**  | 일반 EM보다 낮음 (완전 최적화가 아닌 증가시키는 방식)                                                                                                     | 데이터 수 \(N\)에 대해 독립적인 계산량을 가짐 (한 번에 하나의 데이터만 업데이트)                                                                            |
| **수렴 속도**   | 일반 EM과 비슷하거나 더 빠를 수도 있음                                                                                                              | 일반 EM보다 더 빠르게 수렴할 가능성이 높음                                                                                                    |
| **특징적인 방법** | - M 단계에서 기울기 기반 최적화(Gradient-based optimization) 사용 가능  <br> - 기대 조건부 최대화(ECM, Expectation Conditional Maximization)와 같은 변형 기법 포함 가능 | - 충분 통계량을 사용하여 기존 값을 점진적으로 업데이트 <br> - 배치(batch) 기반이 아니라 데이터 스트림에서도 사용 가능                                                    |
| **활용 예시**   | - M 단계의 최적화가 어려운 경우 (예: 높은 차원의 매개변수 최적화)  <br> - M 단계를 여러 개의 부분 최적화(sub-optimization) 단계로 나누는 경우 (ECM 기법 등)                          | - 온라인 학습(online learning) 또는 실시간(real-time) 데이터 처리  <br> - 점진적 학습(incremental learning) 방식이 필요한 경우 (예: 새로운 데이터가 지속적으로 추가될 때) |

