---
날짜: 2025-01-10
완료: false
tags:
  - DL
---
## Start with
일반적인 데이터는 변수의 순서를 변경하더라도 모델의 성능에는 영향이 없는데, 특정 데이터들(자연어, 이미지)은 변수간의 내재된 종속성이 있다. 
CNN은 이미지 데이터에 특화된 모델로 인접한 파라미터 공유를 활용해 **불변성(invariances)과 등변성(equivariances)** 을 포함함으로써 공강적 특징을 포착하고자 하는 모델 


## CV 응용 분야
- **이미지 분류**: 예를 들어, 피부 병변을 양성 또는 악성으로 분류하는 작업.
- **객체 탐지**: 이미지 내의 객체 위치를 탐지, 예를 들어 자율주행차의 보행자 탐지.
- **이미지 분할**: 각 픽셀을 분류해 동일한 라벨을 가진 영역으로 나누는 작업.
- **캡션 생성**: 이미지에서 자동으로 텍스트 설명 생성.
- **이미지 합성**: 새로운 이미지 생성, 예: 텍스트 기반의 이미지 합성.
- **인페인팅(Inpainting)**: 이미지의 특정 영역을 제거 후 자연스럽게 보완.
- **스타일 변환**: 특정 스타일의 이미지를 다른 스타일로 변환.
- **슈퍼 해상도(Super-resolution)**: 이미지 해상도 개선.
- **깊이 예측(Depth prediction)**: 카메라의 픽셀별로 거리 추정.
- **장면 재구성(Scene reconstruction)**: 3D 장면 재구성.

## Image Data 

이미지 데이터는 픽셀의 직사각형 배열로 구성되며, 각 픽셀은 음영 or RGB채녈 강도 값을 포함합니다. 0~255 사이의 8비트 정수로 표현됩니다.
MRI와 같은 3차원 데이터는 voxel이라는 3차원 그리드로 구성 되며, 2차원 이미지의 연속채로 볼 수 있음
신경망 모델을 이미지 데이터에 적용할 때는 이미지의 구조적 특성을 고려해야함. 이미지의 높은 차원성과 픽셀 간 상호작용을 무시하면, 이미지 데이터의 특성을 전허 반영하지 못하기 때문에 학습이 힘들어진다. 그래서 **Local Correlation**이 중요한데, 가까운 픽셀 간에는 유사한 색상과 강도를 가지는 경향이 있어 이미지 데이터의 강력한 특성을 반영한다.


## Convalutional Filters
- 공간의 특성을 반영한 아키텍처를 설계하는 것이 중요한데, 이는 데이터 요구 사항을 줄이고, 이미지 공간에서의 일반성을 향상 시킬수 있음
- 2차원 구조를 활용하기 위해 4가지 개념을 활용할 수 있는데,
	- hierarchy
	- locality
	- equivariances
	- invariances
- 뉴런이 작은 계층의 특징(가장자리와 같은)을 감지한다면 , 작은 부분만 감지하면된다.
- 복잡한 구조를 계층적으로 이해함으로써 높은 수준의 특징(얼굴과 같은)을 감지 할 수 있다. 

### Feature detectors
- 이미지를 설명하는 식은 $w^{T}x$로 표현된다.
- 최대 출력 응답
	-  ||x||²의 크기가 고정되어 있다고 가정하자
		- 이미지의 크기를 제한한다고 이해 할 수 있음
	- 주어진 유닛에서 $x=\alpha w$의 형태를 가저야한다
		-  x가 가중치 벡터 w와 같은 방향을 가질 때 최대 출력을 얻을 수 있기 때문
	- 이는 은닉 유닛의 최대 출력 응답이 해당 유닛이 커널 이미지와 유사한 패치를 감지할 때 발생하는 것을 의미
- Relu의 역활
	- Relu는  $w^{T}x$가 $-w_{0}$라는 임계값을 초과할 때만 0이 아닌 출력을 생성한다. 따라서, 해당 유닛은 입력 패치가 커널과 충분히 유사하다고 판단 될 때 신호를 생성하는 특징 감지기 로써의 역할을 한다.

### Translation equivariances
- 우리가 cv에서 중요하게 다루는 문제는 물체를 감지하는 것이고, 그 물체의 위치에 따라 결과가 바뀌면 안된다.
- 이 문제를 해결하기 위해 신경망의 가중치를 위치에 따라 복사하는 방식을 사용함
	- 신경망이 한 위치에서 학습한 내용을 이미지의 모든 위치에 적용할 수 있음.
	- 학습 데이터의 모든 위치에서의 사례가 포함 되지 않아도 일반화가 가능하다.
- Feature map
	- 가중치 공유
	- 예를 들어 눈에 반응하는 가중치가 있다면, 이미지 어디서든 같은 방식으로 눈을 감지
- Translation equivariances(변환 등가성) -> 이미지의 한 위치에서 어떤 패턴을 감지하면, 다른 위치에서도 동일한 반응을 생성할 수 있는 속성을 의미
- 이 구조는 sparsity(희소성)을 확인 할수 있다.
	- 모든 신경망의 픽셀이 연결되지 않고, 일부 연결만 활성화 하는 구조를 가짐을 의미

>이를 수학적으로 구현하기 위해 나온게 Convolution 이다

- 작은 필터(커널)가 한칸씩 이동하면서 특정 패턴을 찾는다.
- 필터가 이동하면서 동일한 가중치를 사용하면서 변환 등가성이 보장됨
- $I$라는 이미지에 $K$라는 필터를 씌워서 $C$라는 결과를 얻어 낸다
$$C(j,k)=\sum_{l}\sum_{m}I(j+l,k+m)K(l,m)$$
![[Pasted image 20250111221954.png]]

- 예시
	- 수직 엣지 검출 필터
	- $\begin{bmatrix}-1 & 0 & 1 \\-1 & 0 & 1 \\-1 & 0 & 1\end{bmatrix}$
	- 수직 엣지 검출 필터
	- $\begin{bmatrix} -1 & -1 & -1 \\ 0 & 0 & 0 \\ 1 & 1 & 1 \end{bmatrix}$ 
### Padding
- Convolution 맵의 크기가 일반 맵보다 크기가 작아짐을 확일 할수 있는데, 이를 해결하기 위한 기술
- 원래 이미지에 잉여 픽셀을 추가하는 방식 
- $P = \frac{(M - 1)}{2}$ 로 추가 되어야 Convolution 맵의 크기가 변하지 않는다 , P: 패딩 수, M: 커널의 크기 

### Strided convolution
- Convolution 맵의 크기를 원래 이미지보다 훨씬 작게 줄이기 위한 기술
- 커널이 움직이는 칸수를 1에서 증가시킨다.
- 이점
	- 유연한 네트워크 설계가 가능함
	- 효율적인 다운 샘플링

### Multi-dimensional Convolutions (다차원 컨볼루션)
- 위의 개념들은 한픽셀에 하나의 값이 있다는 전제지만, 사실 이미지는 3개의 채널을 가지고 있음
- 채널수는 일반적으로 $C$로 적으며, 필터의 크기는 $M \times M \times C$ + 1이된다 여기서 1은 bias
- **$1 \times 1$ convolution**
	- 1개의 픽셀에 있는 여러 채널에 입히는 필터
	- C개의 weight와 1개의 bias가 있음
	- 목적
		- 특징 맵에서 채널의 수를 줄이거나 조정하기 위함
		- 입력 채널의 개수와 독립적으로 출력 채널의 개수를 설정할 수 있음

### Polling
- 너무 작은 변화에 민감하게 반응하면, 특징을 잡에 내지 못할 수 도 있는데, 풀링은 이미지에서 작은 변화에 대해 신경망이 불변성을 가지도록 도와주는 기술이다.
- 효과
	- 변화 불변성
		- 위치의 영향을 줄임
		- 정보를 간단하게 요약해줌
		- 해상도를 축소하여 계산속도 증가, 과적합 방지
- 방법
	- **최대 풀링(Max Pooling)**: 영역 내 가장 큰 값을 선택.
	- **평균 풀링(Average Pooling)**: 영역 내 모든 값의 평균을 계산

## Multilayer Convolutions
- 합성곱 신경망(CNN)은 단일 합성곱 층에서 시작하지만, 더 깊은 구조로 확장하기 위한 여러층을 쌓음
- 깊이가 커질수록 복잡한 패턴을 학습할 수 있고, 수용 영역이 점점 커지며, 더 넓은 입력 정보를 학습 할 수 있게 된다.
- 마지막 단계에서는 완전 연결층이 추가되며, 모든 정보를 조합해 최종 출력을 생성
- 다층 합성곱은 매개변수의 수를 줄이는데 도움을 주며, 완전연결층은 최종적으로 독립적인 자유도를 제공
	- 커널의 매개변수를 공유하기 때문