---
날짜: 2025-01-25
완료: false
tags:
  - 딥러닝
  - CNN
---

## Image Segmentation
각 픽셀을 클래스($C$)에 할당하여 더 세부적인 분석이 가능하게 하는 기술

### Convolutional Segmentation
- 고전적인 방식
	- 모든 픽셀에 대하여 CNN 모델을 반복적으로 처리하여 각 필셀마다 클래스를 배정
	- 불필요한 계산이 많고, 매우 비효율적인
- 개선안
	- 서로 다른 위치에서도**포워드 패스**를 하나의 네트워크로 **그룹화** 하여 진행
	- 각 레이어가 입력 이미지와 동일한 차원을 가지며, **패딩과 풀링 없이 스트라이드 1로 작동**하는 CNN을 만듦
		- 픽셀을 따로 처리하지 않고, 이미지를 한 번에 처리하도록 네트워크를 설계
	- 각 출력 유닛은 소프트맥스 활성화 함수와 공유된 가중치를 사용합니다.
	- 하지만 여전히 복잡한 내부 표현 학습에 많은 레이어와 채널이 필요하므로 고해상도 이미지를 처리하기에는 비용이 매우 많이 듦.

### Up-sampling
- 컨볼루션 신경망(CNN)은 일반적으로 **다운샘플링**(strided convolutions나 pooling)을 사용.
    - 채널 수를 증가시키고 특성 맵(feature map)의 크기를 줄여 계산 효율성을 높이면서 의미 있는 고차원 특징(high-order features)을 추출하는 목적
- 하지만, 시맨틱 세그멘테이션에서는 입력 이미지의 해상도를 유지하며 결과를 얻어야 하므로 다운샘플링된 데이터를 다시 **업샘플링**(해상도 복원)하여 복원 해야함
![[Pasted image 20250125084824.png]]


- 평균 풀링 기반 업샘플링
    - 입력 값을 그대로 복사하여 대응하는 출력 블록에 채웁니다.
    - 그림에서 보여지듯이 입력값이 평균 풀링의 역방향으로 매핑됩니다.
    - 입력을 정확히 복원할 수 있음.
- 맥스 풀링 기반 업샘플링 (Max-unpooling)
    - 다운샘플링 단계에서 저장한 최대값의 위치를 사용해 복원합니다.
    - 나머지 값은 0으로 채웁니다.
    - 이는 원본 특성 정보를 더 잘 보존합니다.
![[Pasted image 20250125085124.png]]

### Fully convaolution networks
- 위의 업샘플링 기법들은 학습이 불가능 하다는 특징이 있는데 이를 해결하기 위은 **Transpose Convolution**이라는 기술을 활용
- 다운샘플링이 특정 필터를 사용해 입력 크기를 줄였다면, 업샘플링은 그 반대로 필터를 사용해 입력 크기를 증가.
- 방법
    - 입력 레이어의 작은 패치에 커널(필터)을 곱한 결과를 출력 레이어로 확장합니다.
    - 여러 출력 위치가 겹칠 수 있는데, 이 겹친 영역은 값을 **합산하거나 평균**하여 계산합니다.
![[Pasted image 20250125085703.png]]
- 특징
	- **Pooling 없이 오직 컨볼루션만 사용**하여 다운샘플링과 업샘플링을 처리
	- 입력 이미지가 어떤 크기든 상관없이, 출력이 입력과 동일한 크기의 세그멘테이션 맵을 생성
	- FCN은 필터를 학습해 해상도를 복원하는 동시에, 픽셀 단위의 정밀한 결과를 제공


### U-Net Architecture
위 방법들엔 심각힌 문제가 있는데 그건 바로 **위치 정보(Spatial Information)** 가 손실된다는 점
특히 **시맨틱 세그멘테이션**(픽셀 단위 분류)에서는 이 위치 정보가 매우 중요!!!


- U-Net의 핵심 구조
	-  이름처럼 네트워크가 U자 형태로 설계.
- 대칭 구조
    - 왼쪽 절반: 다운샘플링 → 고차원 특징 추출.
    - 오른쪽 절반: 업샘플링 → 원래 이미지 크기로 복원.
- **스킵 연결(Skip Connection)**
    - 다운샘플링 과정에서 얻은 정보를 업샘플링 단계와 연결(Concatenate)하여 세밀한 정보를 복구.
    - 이로 인해 손실된 위치 정보가 복원되며, 세그멘테이션 성능이 향상됩니다.
- 마지막 단계에서 1×11 컨볼루션을 사용하여 출력 채널 수를 클래스 개수로 줄이고, 소프트맥스 활성화 함수로 픽셀 단위 분류를 수행

![[Pasted image 20250125090302.png]]


## Style Transfer
우리가 알다시피 CNN은 단순 특징 -> 복잡한 특징으로 학습하고, 이후 계층은 객체와 같은 더 복잡한 특징을 학습. 이를 활용해 이미지를 다른 이미지 스타일로 랜더링 할 수 있다 이것을  **신경 스타일 전이**라고 함

$$E(G) = E_{\text{content}}(G, C) + E_{\text{style}}(G, S)
$$
여기서 2개의 이미지를 입력받아 C의 컨탠츠를 가저오고 S의 스타일을 가저와 새로운 이미지 G를 만든다고 생각하면 편함

### 콘탠츠 손실
$$E_{\text{content}}(G, C) = \sum_{i,j,k} \left( a_{ijk}(G) - a_{ijk}(C) \right)^2$$
- 여기서 $a_{ijk}(G)$는 입력 이미지가 $G$일 때, 특정 레이어에서 위치 $(i,j)$와 채널 $k$에서의 사전 활성화(pre-activation)(입력값)를 나타냄
- 저차원 특징(가장자리, 질감)을 더 잘 맞추며, 상위 계층에서는 객체와 같은 고차원 구조를 학습

### 스타일 손실

- 특징이 레이어 내의 다양한 채널에서 발생하는 방식의 일관성을 유지하도록 유도
	- 채널 간의 **공동 발생(co-occurrence)** 패턴
	- 특정 채널 간 상관관계를 측정하기 위해 **교차 상관 행렬**(Style Matrix)을 사용
	- $F_{kk'}(G)$ 는 $G$에서 특징 맵들의 상관 행렬을 나타냄
$$F_{kk'}(G) = \sum_{i=1}^{I} \sum_{j=1}^{J} a_{ijk}(G) a_{ijk'}(G)$$
$$E_{\text{style}}(G, S) = \frac{1}{(2IJK)^2} \sum_{k=1}^{K} \sum_{k'=1}^{K} \left( F_{kk'}(G) - F_{kk'}(S) \right)^2$$
![[Pasted image 20250125100141.png]]