##### \[SIGIR'23] Dynamic Graph Evolution Learning for Recommendation
### Motivation
- GNN 기반 추천 모델들은 시간에 따른 노드의 진화를 무시
- 동적 추천 모델에서의 직관적인 L2 정규화 방식은 모델 학습과 분리되어 있어, 성능이 suboptimal함 (학습에 의해 정규화가 조정되지 않음)
### Intuitive Idea
- **시간에 따라 노드 임베딩을 업데이트하자**
- **정규화 과정을 모델 학습과 연결하자**
- **더 나은 성능을 위해 joint-training을 하자**
### Technical Idea
- 3가지 방식의 효과적인 리얼타임 노드 업데이트
	1. inherent interaction potential (IIP)
	2. time-decay neighbor augmentation (TNA)
	3. symbiotic local structure learning (SLS)
- re-scaling enhancement networks (RENet)
	- 해당 방법을 통해 정규화 과정을 적응적, 자동적으로 모델 학습과 연결
- interaction matching task와 future prediction task를 같이 학습시킴
	- 희소한 그래프에서 정보가 부족한 문제를 완화하기 위함
### Formulation
- Input
- Output
### Method
#### Overview
![[DGEL_1.png]]1. 동적 임베딩 업데이트 3가지 방법 사용
1. RENet으로 동적 임베딩 정규화해 스케일 왜곡을 방지
2. interaction matching task (BPR Loss)와 future prediction task (Evolution Loss)를 joint training해 성능 향상
#### Dynamic Representation Learning
1. **Inherent Interaction Potential** (IIP)
	- 유저 $u_i$와 아이템 $v_j$의 $t$시점에 발생한 **상호작용은 각각의 $t$시점 상태를 표현**하는데 핵심적인 역할을 한다고 가정
	$$
	\begin{align*}
\mathbf{h}_i^t(\text{IIP}) &= \sigma(\mathbf{W}_{11}^u \tilde{\mathbf{h}}_i^{t-1} + \mathbf{W}_{12}^u \tilde{\mathbf{h}}_j^{t-1} + \mathbf{W}_{13}^u f + \mathbf{W}_{14}^u \Delta t_i) \\
\mathbf{h}_j^t(\text{IIP}) &= \sigma(\mathbf{W}_{11}^v \tilde{\mathbf{h}}_j^{t-1} + \mathbf{W}_{12}^v \tilde{\mathbf{h}}_i^{t-1} + \mathbf{W}_{13}^v f + \mathbf{W}_{14}^v \Delta t_j)
\end{align*}
	$$
		- $\mathbf{h}_i^t(\text{IIP}), \mathbf{h}_j^t(\text{IIP})\in \mathbb{R}^\tilde{d}$: $t$시점에 IIP 방식으로 업데이트된 유저 $u_i$와 아이템 $v_j$의 임베딩
		- $\tilde{\mathbf{h}}_i^{t-1}, \tilde{\mathbf{h}}_j^{t-1}$: 이전 시점의 동적 임베딩들
		- $f$: 상호작용 특성
		- $\Delta t_i, \Delta t_j$: 유저 $u_i$와 아이템 $v_j$의 직전 상호작용으로부터 현재 $t$시점까지의 시간 차이 (아무 아이템/유저와의 상호작용을 의미)
		- $\mathbf{W}_{11-13}^u, \mathbf{W}_{11-13}^v \in \mathbb{R}^{\tilde{d}\times \tilde{d}}$: 학습 가능한 가중치 행렬
		- $\mathbf{W}_{14}^u, \mathbf{W}_{14}^v \in \mathbb{R}^\tilde{d}$: 학습 가능한 가중치 벡터
		- 가중치를 유저와 아이템으로 나눠서 설정한건 **서로 다른 수준의 동적 변화를 보이기 때문** (일반적으로 유저가 아이템보다 상호작용에 더 민감하게 반응함) %%우리 아이디어와 비슷한듯%%
		- $\sigma$: 활성화 함수 (Tanh, LeakyReLU)
2. **Time-Decay Neighbor Augmentation** (TNA)
	- 장기적인 동적 속성을 파악하기 위해 **노드의 과거 상호작용들 활용**
	$$
	\begin{align*}
\mathbf{h}_i^t(\text{TNA}) &= \sigma\left(\mathbf{W}_{21}^u \tilde{\mathbf{h}}_i^{t-1} + \sum_{j \in {N}_i} \mathbf{W}_{22}^u \kappa^u \tilde{\mathbf{h}}_j^{t-1} \right) \\
\mathbf{h}_j^t(\text{TNA}) &= \sigma\left(\mathbf{W}_{21}^v \tilde{\mathbf{h}}_j^{t-1} + \sum_{i \in {N}_j} \mathbf{W}_{22}^v \kappa^v \tilde{\mathbf{h}}_i^{t-1} \right)
\end{align*}
	$$
		- $\mathbf{h}_i^t(\text{TNA}), \mathbf{h}_j^t(\text{TNA})\in \mathbb{R}^\tilde{d}$: $t$시점에 TNA 방식으로 업데이트된 유저 $u_i$와 아이템 $v_j$의 임베딩
		- $N_i$: 유저 $u_i$와 상호작용했던 아이템 집합 ($t$시점까지의 snapshot)
		- $N_j$: 아이템 $v_j$와 상호작용했던 유저 집합 ($t$시점까지의 snapshot)
		- $\mathbf{W}_{21,22}^u, \mathbf{W}_{21,22}^v \in \mathbb{R}^{\tilde{d}\times \tilde{d}}$: 학습 가능한 가중치 행렬
		- $\mathcal{k}$: softmax 기반 이웃 별 시간 가중치
			- $\kappa^u(t_i - t_j) = \exp(\tau_{ij}) / \sum_{j \in {N}(i)} \exp(\tau_{ij})$
			- $\tau_{ij}=-(t_i-t_j) / \max(t_i - t_j \mid j \in {N}(i))$
			- 복잡한 time-aware attention score는 추가적인 오버헤드가 필요하므로 이를 사용 (하이퍼파라미터 없고 계산 빠름)
3. **Symbiotic Local Structure Learning** (SLS)
	- 상호작용의 영향과 주변 이웃들의 맥락 (로컬 구조)를동시에 고려
	$$
	\begin{align*}
\mathbf{h}_i^t(\text{SLS}) &= \sigma\big(\mathbf{W}_{31}^u(\tilde{\mathbf{h}}_i^{t-1} - \tilde{\mathbf{h}}_j^{t-1})^p + \mathbf{W}_{32}^u \text{avg}(\{\tilde{\mathbf{h}}_z^{t-1}, \forall z \in {N}_i\}) \\
&\quad + \mathbf{W}_{33}^u \text{avg}(\{\tilde{\mathbf{h}}_x^{t-1}, \forall x \in {N}_j\})\big) \\
\mathbf{h}_j^t(\text{SLS}) &= \sigma\big(\mathbf{W}_{31}^v(\tilde{\mathbf{h}}_j^{t-1} - \tilde{\mathbf{h}}_i^{t-1})^p + \mathbf{W}_{32}^v \text{avg}(\{\tilde{\mathbf{h}}_x^{t-1}, \forall x \in {N}_j\}) \\
&\quad + \mathbf{W}_{33}^v \text{avg}(\{\tilde{\mathbf{h}}_z^{t-1}, \forall z \in {N}_i\})\big)
\end{align*}
	$$
		-  $\mathbf{h}_i^t(\text{SLS}), \mathbf{h}_j^t(\text{SLS})\in \mathbb{R}^\tilde{d}$: $t$시점에 SLS 방식으로 업데이트된 유저 $u_i$와 아이템 $v_j$의 임베딩
		- $(x-y)^p$: 원소별 거듭제곱을 의미 %%이걸 왜 하는지 설명이 없음%%
			- $p=2$면 크기만 고려 (대칭적 학습)
			- $p=1$이면 방향도 고려 (유저와 아이템 각각이 자기 중심적 학습을 하게 함: 유저 업데이트 시 유저에서 아이템을 뺌. 아이템도 마찬가지)
		- $\text{avg}$: average pooling
		- $\mathbf{W}_{31-33}^u, \mathbf{W}_{31-33}^v \in \mathbb{R}^{\tilde{d}\times \tilde{d}}$: 학습 가능한 가중치 행렬
#### Re-scaling Enhancement Network
- 동적 임베딩을 스케일링하기 위해 RENet을 사용 %%DR에 적용한 건 처음이라 주장%%
	$$
	\begin{align*}
	G(\tilde{\mathbf{h}}) &= \sigma_2(\mathbf{w}_2 \sigma_1(\mathbf{W}_1 \tilde{\mathbf{h}} + \mathbf{b}_1) + b_2) \\
	\tilde{\mathbf{h}}^\circ &= G(\tilde{\mathbf{h}}) \cdot \tilde{\mathbf{h}}
	\end{align*}
	$$
	- $G(\cdot)$: re-scaling factor (강도를 적응적으로 조절 가능)
	- $\mathbf{W}_1 \in \mathbb{R}^{\tilde{d}/2\times \tilde{d}}, \mathbf{b}_1 \in \mathbb{R}^{\tilde{d}/2}, \mathbf{w}_2\in \mathbb{R}^{\tilde{d}/2}, b_2 \in \mathbb{R}$: 학습 가능한 가중치들
	- $\sigma_1$: 첫 layer의 활성화 함수 (Tanh, LeakyReLU)
	- $\sigma_2$: 두번째 layer의 활성화 함수 (Leaky ReLU)
	- RENet 외에도 Feed-Forward Network와 같은 re-scaling 방법들 존재 (실험에서 비교함)
- 최종 임베딩은 아래와 같이 정보 손실 방지를 위해 concat으로 구성됨 (각각은 re-scaling한 상태)
	$$
	\begin{align*}
\tilde{\mathbf{h}}_i^t &= \sigma\left(\mathbf{W}_3^u [\mathbf{h}_i^t(\text{IIP}) \| \mathbf{h}_i^t(\text{TNA}) \| \mathbf{h}_i^t(\text{SLS})] + \mathbf{W}_4^u \tilde{\mathbf{h}}_i^{t-1} + \mathbf{b}_3 \right) \\
\tilde{\mathbf{h}}_j^t &= \sigma\left(\mathbf{W}_5^v [\mathbf{h}_j^t(\text{IIP}) \| \mathbf{h}_j^t(\text{TNA}) \| \mathbf{h}_j^t(\text{SLS})] + \mathbf{W}_6^v \tilde{\mathbf{h}}_j^{t-1} + \mathbf{b}_4 \right)
\end{align*}
	$$
	- $\mathbf{W}^u_3\in \mathbb{R}^{\tilde{d}\times 3\tilde{d}}, \mathbf{W}^u_4\in \mathbb{R}^{\tilde{d}\times \tilde{d}}, \mathbf{b}_3\in\mathbb{R}^\tilde{d}$: 학습 가능한 가중치들
	- $\mathbf{W}^v_5\in \mathbb{R}^{\tilde{d}\times 3\tilde{d}}, \mathbf{W}^v_6\in \mathbb{R}^{\tilde{d}\times \tilde{d}}, \mathbf{b}_4\in\mathbb{R}^\tilde{d}$: 학습 가능한 가중치들
#### Multi-Task Joint Training
1. **interaction matching task (BPR Loss)**
	- $t$시점의 상호작용마다 BPR Loss를 계산해 현재 시점에서 얼마나 잘 연결되었는지 측정
	$$
	\mathcal{L}_{bpr} = -\frac{1}{|\mathcal{S}|} \sum_{t=1}^{|\mathcal{S}|} \log(\sigma(s_t^{i,j} - s_t^{i,j^-})), \quad s_t^{i,j} \in \mathcal{S},\ s_t^{i,j^-} \notin \mathcal{S}
	$$
		- $s_t^{i,j}=\tilde{\mathbf{h}}_i^{t}\times \tilde{\mathbf{h}}_j^{t}$: 유저 $u_i$와 positive pair인 아이템 $v_j$의 임베딩끼리의 내적 (실제 상호작용들)
		- $s_t^{i,j-}=\tilde{\mathbf{h}}_i^{t}\times \tilde{\mathbf{h}}_j^{t}$: 유저 $u_i$와 negative pair인 아이템 $v_{j-}$의 임베딩끼리의 내적
		- $\sigma$: 시그모이드 함수
2. **future prediction task (Evolution Loss)**
	- Future Drifting (JODIE와 DGCF와 동일하게 작동: projection)
	$$
	\begin{align*}
\tilde{\mathbf{h}}_i^{*(t+1)} &= \left(1 + \Delta(t+1)\mathbf{w}_1\right) \cdot \tilde{\mathbf{h}}_i^t \\
\tilde{\mathbf{v}}_j^{*(t+1)} &= \mathbf{W}_2 \tilde{\mathbf{h}}_i^{*(t+1)} + \mathbf{W}_3 \bar{\mathbf{h}}_i + \mathbf{W}_4 \tilde{\mathbf{h}}_j^t + \mathbf{W}_5 \bar{\mathbf{h}}_j + \mathbf{b}
\end{align*}
	$$
		- $\tilde{\mathbf{h}}_i^{*(t+1)}$: 유저 $u_i$의 $t+1$시점의 예측된 동적 임베딩
		- $\Delta$: $t$시점과 $t+1$시점의 시간 간격
		- $\bar{\mathbf{h}}_i, \bar{\mathbf{h}}_j$: 유저 $u_i$와 아이템 $v_j$의 정적 임베딩 %%아마 원-핫 벡터?%%
		- $\tilde{\mathbf{v}}_j^{*(t+1)}\in\mathbb{R}^{(\tilde{d}+\bar{d})}$: 유저 $u_i$가 $t+1$시점에 상호작용할 것으로 예측된 아이템 임베딩 
		- $\mathbf{W}_1\in\mathbb{R}^\tilde{d}, \mathbf{W}_{2,4}\in\mathbb{R}^{(\tilde{d}+\bar{d})\times \tilde{d}}, \mathbf{W}_{3,5}\in\mathbb{R}^{(\tilde{d}+\bar{d})\times \bar{d}}, \mathbf{b}\in\mathbb{R}^{\tilde{d}+\bar{d}}$: 학습 가능한 파라미터들
		- $\tilde{\mathbf{v}}_j^{*(t+1)}$와 가까운 top-k 아이템들을 추천해줌
	- 예측된 아이템 임베딩과 실제 아이템 임베딩 간의 Evolution Loss를 계산해 해당 거리를 최소화하도록 함
	$$
	\mathcal{L}_{\text{evol}} = \sum_{i,j,t \in \mathcal{S}} \left\| \tilde{\mathbf{v}}_j^{*(t+1)} - \mathbf{h}_j^{(t+1)} \right\|^2 + \left\| \tilde{\mathbf{h}}_i^t - \tilde{\mathbf{h}}_i^{t-1} \right\|^2 + \left\| \tilde{\mathbf{h}}_j^t - \tilde{\mathbf{h}}_j^{t-1} \right\|^2
	$$
		- 첫 항은 예측된 아이템 임베딩과 실제 아이템 임베딩 간의 L2 거리
			- 실제 아이템 임베딩은 동적, 정적 임베딩을 concat한 것
		- 두번째 세번째 항은 임베딩들이 급격하게 변하지 않도록 하는 정규화 항
3. Joint Training
	- multi-task training을 활용해 두가지 loss를 동시에 최적화
	$$
	\mathcal{L} = \mathcal{L}_{\text{evol}} + \alpha \mathcal{L}_{\text{bpr}} + \delta \|\Theta\|^2
	$$
		- $\Theta$: 모델 전체 학습 파라미터 집합
		- $\alpha$: BPR loss 가중치
		- $\delta$: L2 정규화 항의 가중치
### Experiment
#### Setup
- 데이터셋:
	- Reddit, Wikipedia: JODIE, DGCF에서 사용했던 데이터셋들
	- Foursquare: 10달 동안 도쿄에서 유저가 장소에 체크인한 데이터셋
	![[DGEL_2.png]]
	- 8:1:1로 학습, 검증, 테스트 데이터 분할
	- T-batch 사용
- 베이스라인:
	- Time-LSTM, DeepCoevolve, LatentCross, CTDNE, **DGCF**, FIRE, TREND
- 평가 지표: MRR, Recall@10
- 하이퍼파라미터:
	- AdamW (lr = 1e-3)
	- \# of porpagation layer: 1
	- RENet: 첫 layer의 차원은 입력의 동적 임베딩, 두번째 layer의 차원은 첫 layer의 절반
	- 동적 임베딩 차원: $\{16, 32, 64, 128\}$
	- 과거 이웃 집합 크기: $\{50, 100, 150, 200, 250, 300\}$
	- BPR loss 계수 $\alpha$: $\{0.001, 0.0005\}$ (evolution loss가 너무 작기 때문)
	- 정규화 계수 $\delta$: 1e-2
#### 성능 비교
![[DGEL_3.png]]
- DGEL이 모든 데이터셋에서 다른 베이스라인들보다 가장 뛰어남 (특히, Reddit)
#### Ablation Study
![[DGEL_4.png]]
- IIP만 사용했을 때보다 TNA, SLS를 함께 사용하는게 성능 향상
  $\rightarrow$ collaborative signal을 효과적으로 포착했기 때문
- RENet을 제거하면 성능이 대부분 크게 하락
  $\rightarrow$ 서로 다른 방식으로 생성된 임베딩들의 크기가 다르면 그래프 기반 추천의 성능 하락 %%값이 크면 propagation 시 너무 큰 영향력을 가질 것%%
- 미래의 사용자 임베딩을 예측해 사용하는 Future Drifting이 없으면 성능 하락
#### Feasible Variants 분석
![[DGEL_5.png]]
1. SLS (symbiotic local structure learning)에서 pooling 방법 비교 (기존은 average)
	- Sum은 max나 average보다 경쟁력이 떨어짐
	  $\rightarrow$ 노드 임베딩이 여러번 업데이트되면서 임베딩 값이 증가하는데 Sum은 이를 감당하지 못함
	- SLS가 제일 성능 좋음
2. RENet에서 정규화 방법들 비교
	- RENet 방법이 가장 뛰어남
	- JODIE나 DGCF에서의 L2 정규화보다 더 우수한 성능
3. 동적 임베딩들의 가중 평균 (linear weighted strategy)
	- DGEL의 임베딩 concat 방식이 더 빠른 학습할 수 있고 정보를 더 잘 유지함
	  %%정말 더 빠를까? 차원이 늘어나면 파라미터 수가 많아지는거 아닌가?%%
#### 하이퍼파라미터 민감도 분석
![[DGEL_6.png]]
1. 동적 임베딩 차원
	- Reddit은 많은 상호작용을 가지므로 유저, 아이템 특성을 학습하려면 더 큰 임베딩이 필요함
	- 모든 데이터셋에서 과도하게 높은 차원 (ex. 128)은 오히려 성능이 떨어짐
2. 이웃 수
	- sparsity와 강하게 관련되어 있음
		- Wiki의 경우 가장 sparse하므로 100에서 최고 성능
		- Foursquare의 경우 덜 민감해보임 (데이터 특성으로 이해)
### Contribution
1. 3가지 업데이트 방식을 통해 시간에 따라 진화하는 유저, 아이템의 동적 특성을 효과적으로 포착
2. 동적 임베딩의 정규화 과정을 적응적, 자동적으로 모델 학습과 연결한 최초의 시도
3. 성능을 향상시키고 시간 순서에 따라 노드가 진화하도록 하기 위해 joint training 수행
	- interaction matching task
	- future prediction task