##### Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks (KDD'19)
### 논문의 제목 설명(단어의 의미들 등)
- Predicting Dynamic Embedding Trajectory: 시간에 따라 변하는 임베딩의 궤적를 예측
- Embedding: 유저와 아이템을 각각 표현하는 벡터
- Temporal Interaction Networks: 시간에 따른 상호작용 네트워크

>시간에 따른 상호작용 네트워크에서 임베딩의 변화하는 궤적을 예측하는 것이 해당 논문의 목적
### Problem formulation (풀고자 하는 문제, input, output, 현실에 어떻게 적용될지)
- 풀고자 하는 문제:
	시간에 따라 변화하는 네트워크에서 임베딩의 변화를 예측하는 문제
	ex. 이커머스, 소셜 네트워크 등과 같은 도메인에서는 시간에 따라 유저와 아이템 간 상호작용이 변함. 해당 변화를 효과적으로 모델링하고, 미래의 상호작용을 예측하는 것
- Input:
	시간에 따른 유저-아이템 상호작용 데이터 (Temporal Interaction Networks)
	해당 논문에서는 상호작용 $S$를 아래와 같이 정의함
	$S=(u,i,t,f)$
	$u$: 유저, $i$: 아이템, $t$: 상호작용 시간, $f$: 특성 벡터 (해당 상호작용의 특성)
- Output:
	미래의 특정 시점에서 유저 임베딩 $\hat{u}(t+\Delta)$
	이를 통해 미래의 유저-아이템 상호작용을 예측하거나, 유저의 상태 변화를 예측할 수 있음
### 해결하고자하는 문제 (뭐가 문제고 뭘 해결해야한다고 주장?)
기존 동적 임베딩 방법의 문제점을 4가지 소개함
1. 임베딩 업데이트 시점의 문제
	상호작용이 발생했을 때만 임베딩을 업데이트함
	ex. 이커머스 데이터에서 오늘 구매한 유저의 임베딩은 일주일, 한달이 지나도 변화하지 않음
	따라서 **유저의 행동이 없더라도 임베딩을 시간에 따라 변화시키는 방법이 필요!**
2. 정적 속성과 동적 속성을 모두 반영해야함
	유저 및 아이템의 속성 중 변화하는 속성($\bar{u}, \bar{i}$)이 있고 변화하지 않는 속성($u(t), i(t)$)이 있음
	ex. 유저의 연령과 최근 관심 있는 카테고리, 영화의 장르와 최근 인기도 등
	기존의 방법은 둘 중 하나만을 반영하는 경우가 많음
	따라서 **정적 속성과 동적 속성을 모두 고려하는 통합된 프레임워크가 필요!**
3. 선형 시간 복잡도 문제
	기존 방법들은 추천 순위를 매길 때 각 유저마다 모든 아이템의 점수를 계산했음
	즉, 아이템의 개수 만큼 시간이 필요함 (선형 복잡도)
	**따라서 더욱 빠르게 추천을 수행할 수 있는 방법이 필요!**
4. 시간적 순서를 보존하기 위해 순차 학습 시 스케일링이 힘듦
	기존 모델들은 시간적 순서를 보존하기 위해 상호작용을 순차적으로 학습함
	하지만 해당 방법은 수백만 개의 상호작용 데이터에서는 학습 속도가 굉장히 느림
	따라서 **배치 단위로 학습할 수 있는 모델이 필요!**
### 문제를 해결하기 위해 낸 아이디어
1. 임베딩 업데이트 시점의 문제
>임베딩의 궤적(Embedding Trajectory)을 예측함으로써 특정 미래 시점에서의 임베딩을 얻을 수 있음
2. 정적 속성과 동적 속성을 모두 반영해야함
>각 유저 및 아이템 마다 2개의 임베딩(static, dynamic)을 가지게 함으로써 이를 반영
>두 임베딩(static, dynamic)을 모두 사용해 궤적(trajectory)를 만듦
3. 선형 시간 복잡도 문제
>유저 임베딩을 기반으로 가장 가까운 아이템 임베딩을 찾음 (모든 아이템에 대한 점수 x)
>이때 Locality Sensitive Hashing(LSH) 방법을 사용해 거의 상수 시간에 가까운 추천이 가능함
4. 시간적 순서를 보존하기 위해 순차 학습 시 스케일링이 힘듦
>t-Batch 알고리즘을 도입해 모델이 여러 개의 독립적인 상호작용을 병렬적으로 학습하게 함
>이를 통해 기존 방법(DeepCoevolve) 대비 9.2배 빠른 학습 속도를 달성함
### 그 아이디어를 실현시키기위한 테크니컬 방법/모델 구조
- 임베딩의 정적 속성과 동적 속성을 반영하기 위해 다음과 같이 임베딩을 정의:
	정적 임베딩(static embedding): $\bar{\mathbf{u}}, \bar{\mathbf{i}} \in \mathbb{R}^d$ 각각은 one-hot 벡터로, 시간에 따라 불변
	동적 임베딩(dynamic embedding): $\mathbf{u}(t), \mathbf{i}(t) \in \mathbb{R}^n$ 시간에 따라 변화

따라서 동적 임베딩을 업데이트하고 투영(project)하는 과정이 필요함
아래 그림은 해당 과정을 수행하는 JODIE 모델을 나타냄
![[JODIE_1.png]]
#### 1. Embedding update operation
상호작용 $S=(u,i,t,f)$을 입력받는 2개의 RNN 모델을 통해 각각의 동적 임베딩을 업데이트함 (RNN의 hidden state가 임베딩을 나타냄)
다양한 RNN 변형을 실험했지만 성능이 비슷하거나 떨어지므로, **학습 파라미터가 적은 RNN을 선택**함

2개의 RNN은 서로 재귀적으로 연결되어 있음 (ex. $t$시점의 아이템 임베딩은 $t^-$시점의 유저 임베딩을 입력 받음. $t^-$는 직전 상호작용 시점을 의미)
즉, **유저 임베딩과 아이템 임베딩이 서로 의존하며 동시에 학습됨**

아래는 연산 공식을 나타냄
$$\mathbf{u}(t) = \sigma ( W_1^u \mathbf{u}(t^-) + W_2^u \mathbf{i}(t^-) + W_3^u f + W_4^u \Delta_u )$$
$$\mathbf{i}(t) = \sigma ( W_1^i \mathbf{i}(t^-) + W_2^i \mathbf{u}(t^-) + W_3^i f + W_4^i \Delta_i )$$

- $\mathbf{u}(t), \mathbf{i}(t)$: 시간 $t$에서의 유저 및 아이템 임베딩
- $\mathbf{u}(t−), \mathbf{i}(t−)$: 직전 상호작용 후의 유저 및 아이템 임베딩
- $f$: 상호작용의 특성(feature vector) (예: Reddit 게시글의 텍스트 데이터)
- $\Delta_u$, $\Delta_i$​: 유저 및 아이템이 직전 상호작용 이후 경과한 시간
- $W_u^1, W_u^2, W_u^3, W_u^4​, W_i^1, W_i^2, W_i^3, W_i^4$: 학습 가능한 가중치 행렬
- $\sigma$: 시그모이드 함수
#### 2. Embedding projection operation
해당 연산은 **경과된 시간에 따라 미래의 유저 임베딩 궤적을 예측**함
즉, 유저 임베딩을 미래의 특정 시점으로 투영(project)함으로써 해당 시점에 발생할 상호작용을 예측할 수 있음
아래 그림은 투영 연산을 나타냄
![[JODIE_2.png]]

투영 연산은 유저의 현재 시점 임베딩 $\mathbf{u}(t)$과 경과 시간 $\Delta$을 입력 받음
1. time-context vector $\mathbf{w} \in \mathbb{R}^n$ 생성
	$\mathbf{w} = W_p\Delta$
	$W_p$는 학습 가능한 가중치 행렬이며, 평균이 0인 정규분포로 초기화됨
2. 특정 미래 시점의 유저 임베딩 $\hat{\mathbf{u}}(t+\Delta)$계산
	$\hat{\mathbf{u}}(t+\Delta) = (1+\mathbf{w})*\mathbf{u}(t)$
	여기서 $(1+\mathbf{w})$는 과거 유저 임베딩을 스케일링함
	만약 $\Delta$가 0이면 기존 임베딩과 동일하며, 시간이 지날수록 기존 임베딩에서 멀어지게 됨
	단순 연결(concatenation)을 입력으로 받는 신경망이 비효율적이라는 이전 연구결과에 따라 **Hadamard product(원소별 곱)를 사용**
	임베딩 투영 시 비선형 변환을 추가하면 성능이 저하됨을 실험을 통해 확인했기에 **선형 변환만을 사용**
#### 3. Training to predict next item embedding
각 유저에 대한 모든 아이템의 확률을 계산했던 기존 방법들과 달리, 다음에 상호작용할 것이라 예측된 아이템 임베딩 $\tilde{\mathbf{j}}(t+\Delta)$을 직접 출력함
Locality Sensitive Hashing(LSH) 기법을 활용해 해당 임베딩과 가장 가까운 아이템을 찾음
아이템 임베딩이 업데이트될 때마다 LSH 데이터 구조도 업데이트함

예측된 아이템 임베딩 $\tilde{\mathbf{j}}(t+\Delta)$과 실제 상호작용 아이템의 가장 최근 임베딩 $\mathbf{[}\bar{\mathbf{j}}, \mathbf{j}(t+\Delta^-)\mathbf{]}$의 **유클리드 거리(L2 loss)를 최소화하는 방향으로 학습** ($\mathbf{[]}$는 concatenation을 의미)
$$\|\tilde{\mathbf{j}}(t+\Delta) - \mathbf{[}\bar{\mathbf{j}}, \mathbf{j}(t+\Delta^-)\mathbf{]}\|_2$$
다음에 상호작용할 것이라 예측된 아이템 임베딩 $\tilde{\mathbf{j}}(t+\Delta)$은 투영된 유저 임베딩 $\hat{\mathbf{u}}(t+\Delta)$과 해당 유저가 직전에 상호작용한 아이템 임베딩 $\mathbf{i}(t+\Delta^-)$을 사용해 예측함 (fully connected linear layer)
$$
\tilde{\mathbf{j}}(t+\Delta) = W_1 \mathbf{\hat{u}}(t+\Delta) + W_2 \bar{\mathbf{u}} + W_3 \mathbf{i}(t+\Delta^-) + W_4 \bar{i} + B
$$
- $W_1, W_2, W_3, W_4​$: 학습 가능한 가중치 행렬
- $B$: 편향 벡터 (bias vector)
- 해당 유저가 직전에 상호작용한 아이템 임베딩 $\mathbf{i}(t+\Delta^-)$을 사용하는 이유
	1. $t$에서 $t+\Delta$사이에 아이템 $i$가 다른 유저와 상호작용해 최신 정보를 포함함
	2. 유저가 같은 아이템과 연속적으로 상호작용하는 경향 ($i=j$)이 있어 예측에 도움이 됨

아래는 학습을 위한 손실 함수를 나타냄
$$
Loss = \sum_{(u, i, t, f) \in S} \|\tilde{\mathbf{j}}(t) - [\bar{\mathbf{i}}, \mathbf{i}(t^-)]\|_2 
+ \lambda_U \|\mathbf{u}(t) - \mathbf{u}(t^-)\|_2 
+ \lambda_I \|\mathbf{i}(t) - \mathbf{i}(t^-)\|_2
$$
- 첫 항은 **예측 아이템 임베딩 손실**을 나타내고, 나머지 두 항은 연속적인 유저/아이템 임베딩의 변화가 너무 크지 않도록 하는 **정규화 항**을 나타냄
- $\lambda_U, \lambda_I$: 정규화 강도를 조절하는 하이퍼파라미터
- 부정 샘플링(negative sampling)을 하지 않는다는 점을 주목할만 함
- 매 상호작용마다 손실을 계산해서 학습함

**범주형 예측**(ex. 소셜 네트워크 내 차단 이용자)을 위해 손실 함수에 **교차 엔트로피 손실**(cross-entropy loss)을 추가할 수 있음 (예측 함수를 변경: $\Theta: \mathbb{R}^{n+d} \rightarrow C$)
#### 4. t-Batch: Training data batching
T-LSTM, RRN과 같은 단일 RNN을 사용하는 모델들은 유저들을 다른 배치에 분리해 병렬 학습이 가능 (아이템의 one-hot 벡터를 입력으로 한 BPTT 알고리즘)
하지만, JODIE는 유저와 아이템의 임베딩이 서로 영향을 주는 **상호 재귀적(mutually-recursive) RNN 구조를 가지므로 단순히 유저를 기준으로 배치를 나눌 수 없음**
ex. 같은 아이템과 상호작용한 두 유저의 업데이트가 서로 영향을 줌

따라서 t-Batch 알고리즘을 개발:
	조건 1: 각 배치 내 모든 상호작용은 병렬로 처리할 수 있어야함
	조건 2: 배치의 순서를 유지하며 상호작용들의 시간적 순서를 보장함
	조건 3: 배치가 없어도 같은 임베딩을 만들어야함

- t-Batch 알고리즘 (2단계)
	1. Select 단계
	   가장 작은 타임스탬프를 가진 엣지 집합을 최대로 선택해 배치 생성
	   각 배치에서 동일한 유저/아이템이 중복되지 않게 구성 (**독립적인 엣지 집합**)
	2. Reduce 단계
	   선택된 엣지들을 네트워크에서 제거
	   남은 엣지가 없을 때까지 반복

- t-Batch 알고리즘 구현 방식: 각 상호작용 $S_r$을 배치 $B_k$에 할당 ($k \in [1, \left| \mathcal{I} \right|]$) %%**왜??**%%
	$\text{maxBatch(e,r)}$: 엔티티 $e$와 관련된 가장 최근 배치 인덱스 반환
	해당 함수를 사용해 새로운 상호작용이 할당될 배치의 인덱스는 다음과 같음
	$\text{batch index} = \text{max}(1+\text{maxBatch(u,r)}, 1+\text{maxBatch(i,r)})$
	즉, **유저 $u$와 아이템 $i$가 마지막으로 등장한 배치의 다음 배치로 할당함**
	시간에 따라 정렬된 상호작용들을 1번씩만 보면 되므로 $O(\left| \mathcal{S} \right|)$

>각 배치는 병렬로 처리: 배치 내부엔 독립적인 엣지만 존재하므로 가능
>순차적 의존성을 유지: 같은 유저와 아이템의 연속된 상호작용은 시간 순서대로 배치되므로 가능
### 그 문제를 해결했다고 실험을 통해 빈틈없이 증명하는지
- 두가지 task에 대한 효과성을 검증
	1. 미래 상호작용 예측 (future interaction prediction)
	2. 사용자 상태 변화 예측 (user state change prediction)
- 각 task에 대해 3개의 데이터셋에서 6개의 베이스라인과 비교
	task1의 데이터셋: Reddit, Wikipedia, LastFM
	task2의 데이터셋: Reddit, Wikipedia, MOOC
	Deep recurrent recommender models: **RRN**, **LatentCross**, **Time-LSTM**, **standard LSTM**
	Dynamic co-evolution models: **DeepCoevolve**
	Temporal network embedding models: **CTDNE**
- 모델은 모두 시간순으로 데이터를 나눠 학습 (train, valid, test) %%**Cold Start??**%%
- 동일한 모델 설정
	동적 임베딩 차원 수 128로 고정
	정적 임베딩은 one-hot 벡터
	모두 50 epoch까지 학습
	검증 데이터셋에서 잘 나온 결과를 기준으로 테스트 데이터셋 성능 비교
	
#### 실험 1: 미래 상호작용 예측
![[JODIE_3.png]]
#### 실험 2: 사용자 상태 변화 예측
![[JODIE_4.png]]
>두 실험 결과를 통해 JODIE 이전의 SOTA 모델들을 모두 이김을 확인함
>두 task에 대해 효과적으로 작동한다고 볼 수 있음

#### 실험 3: 실행 시간 실험
![[JODIE_5.png]]
>JODIE와 유사하게 상호 재귀적인 RNN을 사용하는 DeepCoevolve에 비해 9.2배 빠르게 학습함
>t-Batch 알고리즘이 효과적으로 작동한다고 볼 수 있음

#### 실험 4: 학습 데이터 비율에 대한 강건성
![[JODIE_6.png]]
>JODIE는 학습 데이터의 크기에 관계없이 성능이 안정적이며, 베이스라인 모델들을 이김

%%**(a), (b)에서 강건성이 두드러지게 나타나는 거 같고 (c)와 (d)는 그저 데이터의 특성에 따른 결과처럼 보임**%%

#### 실험 5: 임베딩 크기에 대한 강건성
![[JODIE_7.png]]
>임베딩 크기가 작던 크던 성능이 안정적으로 유지되며, 모든 구간에서 베이스라인 모델들을 이김
>JODIE가 정적 임베딩과 동적 임베딩을 함께 활용하기 때문이라 볼 수 있음

%%**위 그래프에서 JODIE의 경우 작아질수록 성능이 향상됨 -> 더 넓은 범위에서 실험했으면 좋았을 것**%%